{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torchvision.disable_beta_transforms_warning();\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "import torchvision.transforms.v2 as t\n",
    "\n",
    "from lightning import LightningModule, LightningDataModule, Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv();\n",
    "\n",
    "from hyperparameters import Hyperparameters\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENETTE = Path.home() / \"datasets\" / \"imagenette\"\n",
    "\n",
    "CHECKPOINTS_DIR = Path.cwd() / \"checkpoints\"\n",
    "CHECKPOINTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "LOGS_DIR = Path.cwd() / \"logs\"\n",
    "LOGS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_batch(batch: tuple[torch.Tensor, torch.Tensor], le: LabelEncoder, df: pd.DataFrame) -> None:\n",
    "    images, targets = batch\n",
    "    labels = le.inverse_transform(targets.ravel())\n",
    "    labels = [df.loc[x].label for x in labels]\n",
    "    assert images.shape[0] == targets.shape[0], \"#images != #targets\"\n",
    "\n",
    "    subplot_dims:tuple[int, int]\n",
    "    if images.shape[0] <= 8:\n",
    "        subplot_dims = (1, images.shape[0])\n",
    "    else:\n",
    "        subplot_dims = (int(np.ceil(images.shape[0]/8)), 8)\n",
    "\n",
    "    figsize = 20\n",
    "    figsize_factor = subplot_dims[0] / subplot_dims[1]\n",
    "    _, axes = plt.subplots(nrows = subplot_dims[0], \n",
    "                           ncols = subplot_dims[1], \n",
    "                           figsize = (figsize, figsize * figsize_factor))\n",
    "    for idx, ax in enumerate(axes.ravel()):\n",
    "        ax.imshow(images[idx].permute(1, 2, 0))\n",
    "        ax.tick_params(axis = \"both\", which = \"both\", \n",
    "                       bottom = False, top = False, \n",
    "                       left = False, right = False,\n",
    "                       labeltop = False, labelbottom = False, \n",
    "                       labelleft = False, labelright = False)\n",
    "        ax.set_xlabel(f\"{labels[idx]}({targets[idx].item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen = True, repr = True)\n",
    "class Hyperparameters:\n",
    "    task: str\n",
    "    random_seed: int\n",
    "    num_classes: int\n",
    "    metrics: list[str]\n",
    "\n",
    "    criterion: Callable | str\n",
    "    optimizer: Callable | str  \n",
    "    learning_rate: float\n",
    "    momentum: float\n",
    "    weight_decay: float\n",
    "\n",
    "    batch_size: int\n",
    "    grad_accum: int\n",
    "    test_split: float\n",
    "    transform : list[str]\n",
    "\n",
    "    num_workers: int\n",
    "\n",
    "    def get_dict(self) -> dict:\n",
    "        return asdict(self)\n",
    "\n",
    "    def get_datamodule_dict(self) -> dict:    \n",
    "        return {\n",
    "            \"batch_size\": self.batch_size // self.grad_accum,\n",
    "            \"transform\": self.transform,\n",
    "            \"test_split\": self.test_split,\n",
    "\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }\n",
    "\n",
    "    def get_litmodule_hparams(self) -> dict:\n",
    "        return {\n",
    "            \"task\": self.task,\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"metrics\": self.metrics,\n",
    "\n",
    "            \"criterion\": self.criterion,\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"momentum\": self.momentum,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "\n",
    "            \"num_workers\": self.num_workers,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataLoader(dp.iter.IterDataPipe):\n",
    "    def __init__(self, \n",
    "                 src_dp: dp.iter.IterDataPipe, \n",
    "                 label_encoder: LabelEncoder,\n",
    "                 transform: Callable | None = None):\n",
    "        self.src_dp  = src_dp \n",
    "        self.le = label_encoder\n",
    "        self.transform = transform if transform else self._default_transform\n",
    "    \n",
    "    def __iter__(self): \n",
    "        for path, label in self.src_dp:\n",
    "            image = self._load_image(path)\n",
    "            image = self._minmax_image(image)\n",
    "            image = self.transform(image) #type: ignore\n",
    "            label = self._encode_label(label)\n",
    "            yield (image, label)\n",
    "     \n",
    "    def _load_image(self, image_path: Path) -> torch.Tensor:\n",
    "        image = (iio.imread(uri = image_path,\n",
    "                           plugin = \"pillow\",\n",
    "                           extension = \".jpg\")\n",
    "                    .squeeze())\n",
    "\n",
    "        #Duplicate Grayscale Image\n",
    "        if image.ndim == 2:\n",
    "            image = np.stack((image,)*3, axis = -1)\n",
    "        assert image.shape[-1] == 3, \"Not A 3 Channel Image\"\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        image = image.astype(np.float32)\n",
    "        return torch.from_numpy(image)\n",
    "\n",
    "    def _encode_label(self, label) -> torch.Tensor:\n",
    "        return torch.tensor(\n",
    "            self.le.transform([label])[0], #type: ignore\n",
    "        dtype = torch.long)\n",
    "    \n",
    "    def _minmax_image(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    def _default_transform(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        return t.Compose([\n",
    "            t.Resize((256, 256), antialias=True),\n",
    "        ])(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetteDataModule(LightningDataModule):\n",
    "    def __init__(self, root: Path, params: Hyperparameters, transform: Callable | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        if not self.root.is_dir():\n",
    "            self.root.mkdir(parents = True)\n",
    "        self.transform = transform\n",
    "        self.batch_size = (params.batch_size // params.grad_accum)\n",
    "\n",
    "        #TODO: Figure out how to automate getting num_workers\n",
    "        #os.cpu_count or something like that\n",
    "        self.num_workers = params.num_workers\n",
    "\n",
    "        self.save_hyperparameters(params.get_datamodule_dict(),\n",
    "            ignore = [\"transform\", \"params\"])\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if self._is_empty_dir(self.root):\n",
    "            url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\"  \n",
    "            print(\"Root is Empty, Downloading Dataset\")\n",
    "            archive: Path = self.root / \"archive.tgz\"\n",
    "            self._download_from_url(url, archive)\n",
    "            print(\"Extracting Dataset\")\n",
    "            self._extract_tgz(archive, self.root)\n",
    "            print(\"Deleting Archive\")\n",
    "            archive.unlink(missing_ok=True)\n",
    "            print(\"Moving Items to Root\")\n",
    "            self._move_dir_up(self.root / \"imagenette2\")\n",
    "            print(\"Done!\")\n",
    "    \n",
    "    def setup(self, stage: str) -> None:\n",
    "        self._setup_local()\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = self._prepare_local_train()\n",
    "            self.val_dataset = self._prepare_local_val() \n",
    "        \n",
    "        elif stage == \"validate\":\n",
    "            self.val_dataset = self._prepare_local_val()\n",
    "\n",
    "        elif stage == \"test\":\n",
    "            self.val_dataset = self._prepare_local_val()\n",
    "\n",
    "        elif stage == \"predict\":\n",
    "            self.val_dataset = self._prepare_local_val()\n",
    "        \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset = self.train_dataset, \n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "            #persistent_workers = True,\n",
    "            pin_memory = True,\n",
    "            shuffle = True\n",
    "            )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset = self.val_dataset, \n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "            pin_memory = True\n",
    "            )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset = self.val_dataset, \n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "            )\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset = self.val_dataset, \n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "            )\n",
    "\n",
    "    def _setup_local(self) -> None:\n",
    "        df = pd.read_csv(self.root/\"noisy_imagenette.csv\")\n",
    "        df[\"label\"] = df[\"noisy_labels_0\"]\n",
    "        df[\"path\"] = df[\"path\"].apply(lambda x: self.root / x)\n",
    "\n",
    "        self.train_df = df[[\"path\", \"label\"]][df[\"is_valid\"] == False].reset_index(drop = True)\n",
    "        self.val_df = df[[\"path\", \"label\"]][df[\"is_valid\"] == True].reset_index(drop = True)\n",
    "\n",
    "        self._prepare_label_encoder(df[\"label\"].unique().tolist())\n",
    "\n",
    "    def _prepare_local_train(self) -> Any:\n",
    "        pipe = self._datapipe_from_dataframe(self.train_df)\n",
    "        pipe = (pipe \n",
    "                    .shuffle(buffer_size=len(self.train_df))\n",
    "                    #.sharding_filter()\n",
    "                    #.pinned_memory()\n",
    "                    #.load_image_data()\n",
    "                    #.prefetch()\n",
    "                    #.set_length()\n",
    "                )\n",
    "        pipe = ImageDataLoader(pipe, self.label_encoder, self.transform) #type:ignore \n",
    "        pipe = pipe.prefetch(self.batch_size)\n",
    "        pipe = pipe.set_length(len(self.train_df))\n",
    "        return pipe\n",
    "\n",
    "    def _prepare_local_val(self) -> Any:\n",
    "        pipe = self._datapipe_from_dataframe(self.val_df)\n",
    "        pipe = ImageDataLoader(pipe, self.label_encoder) #type: ignore\n",
    "        pipe = pipe.set_length(len(self.val_df))\n",
    "        return pipe\n",
    "\n",
    "    def _datapipe_from_dataframe(self, dataframe: pd.DataFrame) -> Any:\n",
    "        return dp.iter.Zipper(\n",
    "            dp.iter.IterableWrapper(dataframe.path),\n",
    "            dp.iter.IterableWrapper(dataframe.label)\n",
    "            )\n",
    "    \n",
    "    def _prepare_label_encoder(self, class_names: list) -> None:\n",
    "        self.label_encoder = LabelEncoder().fit(sorted(class_names))\n",
    "\n",
    "    def _download_from_url(self, url: str, local_filename: Path) -> None:\n",
    "        response = requests.head(url)\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        with requests.get(url, stream=True) as response:\n",
    "            with open(local_filename, \"wb\") as output_file:\n",
    "                with tqdm(\n",
    "                    total=file_size, unit=\"B\", unit_scale=True, unit_divisor=1024\n",
    "                ) as progress_bar:\n",
    "                    for data in response.iter_content(chunk_size=1024*1024):\n",
    "                        output_file.write(data)\n",
    "                        progress_bar.update(len(data))\n",
    "    \n",
    "    def _extract_tgz(self, tgz_file, out_dir) -> None: \n",
    "        with tarfile.open(tgz_file, \"r:gz\") as tar:\n",
    "            tar.extractall(out_dir)\n",
    "        \n",
    "    def _is_empty_dir(self, path: Path) -> bool:\n",
    "        return not list(path.iterdir())\n",
    "        \n",
    "    def _move_dir_up(self, source_dir: Path) -> None:\n",
    "        for path in source_dir.iterdir():\n",
    "            dest_path = source_dir.parent / path.name\n",
    "            if path.is_dir():\n",
    "                path.rename(dest_path)\n",
    "            else:\n",
    "                shutil.move(path, dest_path)\n",
    "        source_dir.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(LightningModule):\n",
    "    def __init__(self, model, params: Hyperparameters):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        #TODO : Add dicts for Metrics, Optimizers, Criterions\n",
    "        #TODO : Remove Dependence on Hyperparameters Class, locally store stuff\n",
    "\n",
    "        self._set_metrics()\n",
    "        self.save_hyperparameters(\n",
    "            {i:params.get_litmodule_hparams()[i] \n",
    "             for i in params.get_litmodule_hparams().keys() if i!='criterion'},\n",
    "            ignore = [\"model\", \"params\"]\n",
    "        ) \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x, _ = batch\n",
    "        return self.model(x)\n",
    "\n",
    "    def _forward_pass(self, batch, metrics : Callable | None = None):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        if metrics:\n",
    "            metrics(y_pred, y) \n",
    "        return self.params.criterion(y_pred, y) #type: ignore\n",
    "\n",
    "    def _set_metrics(self):\n",
    "        #self.train_metrics = torchmetrics.Accuracy(\"multiclass\", \n",
    "                                    #num_classes=self.params.num_classes,\n",
    "                                    #average = \"macro\")\n",
    "\n",
    "        #self.test_metrics = torchmetrics.Accuracy(\"multiclass\",\n",
    "                                    #num_classes=self.params.num_classes, \n",
    "                                    #average = \"macro\")\n",
    "\n",
    "        #self.val_metrics = torchmetrics.Accuracy(\"multiclass\",\n",
    "                                    #num_classes=self.params.num_classes, \n",
    "                                    #average = \"macro\")\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        #self.log(\"train_acc\", self.train_metrics, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch)#, self.test_metrics)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        #self.log(\"test_acc\", self.test_metrics, on_epoch=True, on_step=False)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch)#, self.val_metrics)\n",
    "        self.log(\"val_loss\", loss, on_step = False, on_epoch = True)\n",
    "        #self.log(\"val_acc\", self.val_metrics, on_epoch=True, on_step=False)\n",
    "      \n",
    "    def configure_optimizers(self):\n",
    "        return self.params.optimizer(self.model.parameters(), #type: ignore\n",
    "                                     lr = self.params.learning_rate,\n",
    "                                     #momentum = 0.9, weight_decay = 5e-4\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_checkpoint = ModelCheckpoint(\n",
    "    dirpath=CHECKPOINTS_DIR,\n",
    "    filename=\"{epoch}-{train_loss:2f}-{val_loss:2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "local_logger = CSVLogger(\n",
    "    save_dir=Path.cwd(),\n",
    "    name=\"logs\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "#wandb.finish()\n",
    "#wandb_logger = WandbLogger(\n",
    "    #save_dir=LOGS_DIR,\n",
    "    #project=\"ilsvrc-with-imagenette\",\n",
    "    #log_model=True,\n",
    "    #version='2',\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Hyperparameters(\n",
    "    task = \"multiclass_classification\",\n",
    "    random_seed = 42,\n",
    "    num_classes = 10,\n",
    "    metrics = [\"accuracy\", \"f1score\"],\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(),\n",
    "    optimizer = torch.optim.Adam,\n",
    "    learning_rate = 1e-6,\n",
    "    momentum = 0,\n",
    "    weight_decay = 0,\n",
    "\n",
    "    batch_size = 128,\n",
    "    grad_accum = 4,\n",
    "    test_split = .3,\n",
    "    transform = [\"random_crop_224\"],\n",
    "    num_workers = 8,\n",
    "\n",
    ")\n",
    "\n",
    "seed_everything(experiment.random_seed, workers = True);\n",
    "alexnet_pretrained = alexnet(weights = \"DEFAULT\")\n",
    "alexnet_pretrained.classifier[-1] = torch.nn.Linear(\n",
    "                                        in_features=4096,\n",
    "                                        out_features=experiment.num_classes,\n",
    "                                        bias = True) \n",
    "#alexnet_transform = AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
    "alexnet_transform = t.Compose([\n",
    "    t.Resize(size = (256, 256), antialias = True),\n",
    "    t.RandomCrop(size = (224, 224), pad_if_needed = True),\n",
    "    #t.RandomHorizontalFlip(p = .5)\n",
    "])\n",
    "\n",
    "classifier = ClassificationModel(alexnet_pretrained, experiment)\n",
    "imagenette_dm = ImagenetteDataModule(\n",
    "        root = IMAGENETTE, \n",
    "        params = experiment, \n",
    "        transform = alexnet_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    #fast_dev_run=True,\n",
    "    #deterministic=True,\n",
    "    #benchmark=True,\n",
    "    #enable_checkpointing=False,\n",
    "    callbacks=[local_checkpoint],\n",
    "    logger=[local_logger],\n",
    "\n",
    "    max_epochs = 20,  \n",
    "    accumulate_grad_batches = experiment.grad_accum,\n",
    "    check_val_every_n_epoch = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ckpt = CHECKPOINTS_DIR / \"last.ckpt\"\n",
    "last_ckpt = last_ckpt if last_ckpt.is_file() else None\n",
    "\n",
    "trainer.fit(\n",
    "    model = classifier,\n",
    "    datamodule = imagenette_dm,\n",
    "    ckpt_path = last_ckpt #type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"labels.csv\", index_col=0)\n",
    "labels_df[\"label\"] = labels_df[\"label\"].str.strip(',')\n",
    "\n",
    "def prepare_preds(dm) -> Any:\n",
    "    dm.setup(\"predict\")\n",
    "    pipe = dm._datapipe_from_dataframe(dm.val_df)\n",
    "    pipe = ImageDataLoader(pipe, dm.label_encoder) #type: ignore\n",
    "    pipe = pipe.shuffle()\n",
    "    pipe = pipe.set_length(len(dm.val_df))\n",
    "    return pipe\n",
    "\n",
    "images = list()\n",
    "labels = list()\n",
    "labels_str = list()\n",
    "\n",
    "dataset = prepare_preds(imagenette_dm) \n",
    "for idx, sample in enumerate(dataset):\n",
    "    if idx >= 64: \n",
    "        break\n",
    "    image = sample[0].clip(0, 1)\n",
    "    label = sample[1]\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "    label = imagenette_dm.label_encoder.inverse_transform([sample[1]])[0]\n",
    "    label = labels_df.loc[label].label\n",
    "    labels_str.append(label)\n",
    "\n",
    "images = torch.stack(images)\n",
    "labels = torch.stack(labels)\n",
    "sample_batch = (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(len(labels_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [(image, label) for image, label in zip(images, labels)]\n",
    "dl = DataLoader(\n",
    "    dataset = sample, #type: ignore\n",
    "    batch_size = 64 \n",
    ")\n",
    "predictions = trainer.predict(\n",
    "    model = classifier,\n",
    "    dataloaders = dl,\n",
    ")\n",
    "preds = predictions[0].argmax(axis = 1)\n",
    "\n",
    "print(preds.shape)\n",
    "preds_batch = (images, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_batch(preds_batch, imagenette_dm.label_encoder, labels_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
