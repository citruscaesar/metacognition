{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning();\n",
    "\n",
    "import torchvision.transforms.v2 as t\n",
    "import torchmetrics\n",
    "from lightning import LightningModule, Trainer, seed_everything\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv();\n",
    "\n",
    "from hyperparameters import Hyperparameters\n",
    "from datamodules import ImagenetteDataModule, viz_batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENETTE = Path.home() / \"dev\" / \"datasets\" / \"imagenette\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(LightningModule):\n",
    "    def __init__(self, model, params: Hyperparameters):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.model = model\n",
    "        \n",
    "        self._set_metrics()\n",
    "        self.save_hyperparameters(\n",
    "            {i:params.get_dict()[i] for i in params.get_dict().keys() if i!='criterion'},\n",
    "            ignore = [\"model\"]\n",
    "        ) \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x, _ = batch\n",
    "        return self.model(x)\n",
    "\n",
    "    def _set_metrics(self):\n",
    "        self.train_metrics = torchmetrics.Accuracy(\"multiclass\", \n",
    "                                    num_classes=self.params.num_classes,\n",
    "                                    average = \"micro\")\n",
    "        self.test_metrics = torchmetrics.Accuracy(\"multiclass\",\n",
    "                                    num_classes=self.params.num_classes, \n",
    "                                    average = \"micro\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch, self.train_metrics)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch = True)\n",
    "        self.log(\"train_acc\", self.train_metrics, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch, self.test_metrics)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", self.test_metrics, on_epoch=True, on_step=False)\n",
    "    \n",
    "    #def validation_step(self, batch, batch_idx):\n",
    "        #loss = self._forward_pass(batch, self.val_metrics)\n",
    "        #self.log(\"val_loss\", loss)\n",
    "      \n",
    "    def configure_optimizers(self):\n",
    "        return self.params.optimizer(self.model.parameters(), \n",
    "                                     lr = self.params.learning_rate)\n",
    "\n",
    "    def _forward_pass(self, batch, metrics):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        metrics(y_pred, y) \n",
    "        return self.params.criterion(y_pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "experiment = Hyperparameters(\n",
    "    task = \"multiclass_classification\",\n",
    "    random_seed = 42,\n",
    "    num_classes = 10,\n",
    "    test_split = .3,\n",
    "    metrics = [\"accuracy\", \"f1score\"],\n",
    "\n",
    "    learning_rate = 1e-6,\n",
    "    batch_size =  16,\n",
    "    num_workers = 4,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    criterion = torch.nn.CrossEntropyLoss(),\n",
    "\n",
    "    local_cache_limit=0\n",
    ")\n",
    "seed_everything(experiment.random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenette_dl = ImagenetteDataModule(IMAGENETTE, experiment)\n",
    "alexnet = torchvision.models.AlexNet(experiment.num_classes)\n",
    "classifier = ClassificationModel(alexnet, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger = True,\n",
    "    max_epochs = 50 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | model         | AlexNet            | 57.0 M\n",
      "1 | train_metrics | MulticlassAccuracy | 0     \n",
      "2 | test_metrics  | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "57.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.179   Total estimated model params size (MB)\n",
      "c:\\Users\\SambhavChandra\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:268: You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "c:\\Users\\SambhavChandra\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\SambhavChandra\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:121: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6caa1da0b34607baf8adeb06898050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SambhavChandra\\miniconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model = classifier, datamodule = imagenette_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
