{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version: 1.13.1+cu117\n",
      "PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pytorch Version: {torch.__version__}\")\n",
    "print(torch.__config__.show())\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(\n",
    "    root = '/media/sambhav/30AC4696AC46568E/datasets',\n",
    "    train = True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((.5, ), (.5,))])\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root = '/media/sambhav/30AC4696AC46568E/datasets',\n",
    "    train = False,\n",
    "    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((.5, ), (.5,))])\n",
    ")\n",
    "\n",
    "#train_dataset.data.to(DEVICE)\n",
    "#train_dataset.targets.to(DEVICE)\n",
    "#test_dataset.data.to(DEVICE)\n",
    "#test_dataset.targets.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = torch.randint(1, len(train_dataset), (1,)).item()\n",
    "img, label = train_dataset.__getitem__(idx)\n",
    "plt.axis('off')\n",
    "plt.imshow(img.squeeze(), cmap = 'gray')\n",
    "print(img.shape)\n",
    "print(img.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "NUM_EPOCHS = 40 \n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True, \n",
    "    num_workers = NUM_WORKERS)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = torch.nn.Flatten(start_dim = 1, end_dim = -1)\n",
    "        self.linear1 = torch.nn.Linear(28 * 28, 1000)\n",
    "        self.linear2 = torch.nn.Linear(1000, 500)\n",
    "        self.linear3 = torch.nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, criterion, optimizer):\n",
    "    num_batches = len(dataloader)\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "        data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        model.train()\n",
    "        prediction = model(data) \n",
    "\n",
    "        loss = criterion(prediction, targets) \n",
    "        epoch_loss += loss.item() / num_batches\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(dataloader, model, criterion):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        num_batches = len(test_loader)\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "        model.eval()\n",
    "        for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "            data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "            prediction = model(data)\n",
    "            predicted_labels = prediction.argmax(1)\n",
    "\n",
    "            loss = criterion(prediction, targets)\n",
    "            epoch_loss += loss.item() / num_batches\n",
    "\n",
    "            correct += (prediction.argmax(1) == targets).int().sum().item() / len(test_dataset)\n",
    "            accuracy = correct*100\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:>.2f}, Test Loss: {epoch_loss}\")\n",
    "        return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinymodel = TinyModel().to(DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tinymodel.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.80, Test Loss: 1.1657489690051717\n",
      "Accuracy: 73.68, Test Loss: 0.9230888123345223\n",
      "Accuracy: 74.62, Test Loss: 0.9102463338785106\n",
      "Accuracy: 73.64, Test Loss: 0.9314931414689231\n",
      "Accuracy: 74.06, Test Loss: 0.9156882546509904\n",
      "Accuracy: 74.31, Test Loss: 0.9129131128833551\n",
      "Accuracy: 75.11, Test Loss: 0.898957104629772\n",
      "Accuracy: 75.42, Test Loss: 0.8840734856143879\n",
      "Accuracy: 74.74, Test Loss: 0.9033633554057712\n",
      "Accuracy: 77.75, Test Loss: 0.7851580865443892\n",
      "Accuracy: 78.72, Test Loss: 0.7583447417635824\n",
      "Accuracy: 78.53, Test Loss: 0.7590067707429264\n",
      "Accuracy: 78.53, Test Loss: 0.773053901020888\n",
      "Accuracy: 80.24, Test Loss: 0.7682157551786699\n",
      "Accuracy: 79.93, Test Loss: 0.7724615449358699\n",
      "Accuracy: 78.70, Test Loss: 0.7698991617579365\n",
      "Accuracy: 81.24, Test Loss: 0.5646802930125764\n",
      "Accuracy: 81.27, Test Loss: 0.5838429303305922\n",
      "Accuracy: 80.99, Test Loss: 0.5969329169791215\n",
      "Accuracy: 81.27, Test Loss: 0.5768860658262946\n",
      "Accuracy: 80.96, Test Loss: 0.5863389500007508\n",
      "Accuracy: 81.46, Test Loss: 0.6010472599867803\n",
      "Accuracy: 81.09, Test Loss: 0.6051523258351978\n",
      "Accuracy: 81.45, Test Loss: 0.5962011278814573\n",
      "Accuracy: 81.60, Test Loss: 0.6151485834152077\n",
      "Accuracy: 81.18, Test Loss: 0.6267276824849427\n",
      "Accuracy: 81.70, Test Loss: 0.6387960024320398\n",
      "Accuracy: 81.42, Test Loss: 0.6418488638321307\n",
      "Accuracy: 81.40, Test Loss: 0.65359095593167\n",
      "Accuracy: 81.17, Test Loss: 0.656798547999874\n",
      "Accuracy: 81.56, Test Loss: 0.6593849781046437\n",
      "Accuracy: 80.70, Test Loss: 0.7151841181478682\n",
      "Accuracy: 81.28, Test Loss: 0.6662337808472336\n",
      "Accuracy: 81.12, Test Loss: 0.6772355471447016\n",
      "Accuracy: 81.35, Test Loss: 0.7125866682666128\n",
      "Accuracy: 80.78, Test Loss: 0.7187447718753935\n",
      "Accuracy: 81.59, Test Loss: 0.7035039553217061\n",
      "Accuracy: 81.35, Test Loss: 0.7499710703921166\n",
      "Accuracy: 80.42, Test Loss: 0.7525951763626879\n",
      "Accuracy: 81.50, Test Loss: 0.7236254991619446\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train_one_epoch(train_loader, tinymodel, criterion, optimizer)\n",
    "    test_loss, accuracy = test_one_epoch(test_loader, tinymodel, criterion)\n",
    "    \n",
    "    writer.add_scalar(\"Train / Loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Test / Loss\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Test / Accuracy\", accuracy, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
