{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msambhav-chandra\u001b[0m (\u001b[33mmetacognition\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version: 1.13.1\n",
      "PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192829337\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pytorch Version: {torch.__version__}\")\n",
    "print(torch.__config__.show())\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA = pathlib.Path(\"/media/sambhav/30AC4696AC46568E/datasets\")\n",
    "\n",
    "DATA = pathlib.Path.home() / \"datasets\"\n",
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5, ), (.5,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root = DATA.as_posix(),\n",
    "    #download = True,\n",
    "    train = True,\n",
    "    transform = transforms\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root = DATA.as_posix(),\n",
    "    train = False,\n",
    "    transform= transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = torch.randint(1, len(train_dataset), (1,)).item()\n",
    "img, label = train_dataset.__getitem__(idx)\n",
    "plt.axis('off')\n",
    "plt.imshow(img.squeeze(), cmap = 'gray')\n",
    "print(img.shape)\n",
    "print(img.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Flatten(start_dim = 1, end_dim = -1)\n",
    "        self.linear1 = nn.Linear(28 * 28, 1000)\n",
    "        self.linear2 = nn.Linear(1000, 512)\n",
    "        self.linear3 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "class TinyClassifier(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate, ):\n",
    "        super().__init__()\n",
    "        self.model = model  \n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.accuracy = torchmetrics.Accuracy(task = \"multiclass\", num_classes=10)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_evaluation_step(self, batch, batch_idx):\n",
    "        data, targets = batch\n",
    "        prediction = self.model(data) \n",
    "        loss = self.criterion(prediction, targets)\n",
    "        accuracy = self.accuracy(prediction, targets) * 100\n",
    "        return loss, accuracy\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #data, targets = batch\n",
    "        #prediction = self.model(data) \n",
    "        #loss = self.criterion(prediction, targets)\n",
    "        loss, _ = self._shared_evaluation_step(batch, batch_idx)\n",
    "        self.log(\"train/loss\", loss, on_epoch=True, prog_bar=True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self._shared_evaluation_step(batch, batch_idx)\n",
    "        metrics = {\"val/loss\": loss, \"val/accuracy\": accuracy}\n",
    "        self.log_dict(metrics)\n",
    "        #self.log(\"val/loss\", loss, on_epoch=True, prog_bar=True, logger = True)\n",
    "        #self.log(\"test/accuracy\", self.val_accuracy(prediction, targets)*100, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self._shared_evaluation_step(batch, batch_idx)\n",
    "        metrics = {\"test/loss\": loss, \"test/accuracy\": accuracy}\n",
    "        self.log_dict(metrics)\n",
    "        #self.log(\"test/loss\", loss, on_epoch=True, prog_bar=True, logger = True)\n",
    "        #self.log(\"test/accuracy\", self.test_accuracy(prediction, targets)*100, on_epoch=True, prog_bar=True, logger=True)\n",
    " \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "class Config():\n",
    "    def __init__(self, num_epochs, batch_size, learning_rate, seed):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seed = seed\n",
    "\n",
    "        self.num_workers = 4\n",
    "    \n",
    "    def log_config(self):\n",
    "        config_dictionary = {\n",
    "            \"num_epochs\" : self.num_epochs,\n",
    "            \"batch_size\" : self.batch_size,\n",
    "            \"learning_rate\" : self.learning_rate,\n",
    "            \"seed\": self.seed\n",
    "        }\n",
    "        return config_dictionary\n",
    "\n",
    "config = Config(10, 64, 1e-3, seed = 69420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset, \n",
    "    batch_size = config.batch_size, \n",
    "    shuffle = True, \n",
    "    num_workers = config.num_workers)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = config.batch_size,\n",
    "    num_workers = config.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"learning_rate\": 0.001\n"
     ]
    }
   ],
   "source": [
    "classifier = TinyClassifier(TinyModel(), config.learning_rate)\n",
    "print(classifier.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | TinyModel          | 1.3 M \n",
      "1 | accuracy  | MulticlassAccuracy | 0     \n",
      "2 | criterion | CrossEntropyLoss   | 0     \n",
      "-------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.211     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b6e2dea2f849608e8f2e2738c368b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a833f8e4ab47ebaa304d051df2ea38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/accuracy          85.1500015258789\n",
      "        test/loss           0.4214544892311096\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 0.4214544892311096, 'test/accuracy': 85.1500015258789}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = TinyClassifier(TinyModel(), config.learning_rate)\n",
    "trainer = pl.Trainer(accelerator = \"gpu\", \n",
    "                     max_epochs = config.num_epochs, \n",
    "                     limit_train_batches = 0.2)\n",
    "\n",
    "trainer.fit(classifier, train_loader)\n",
    "trainer.test(classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
