{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning();\n",
    "\n",
    "import torchvision.transforms.v2 as t\n",
    "from torchvision.models import AlexNet\n",
    "\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from streaming import StreamingDataset, MDSWriter\n",
    "from streaming.base.util import clean_stale_shared_memory\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv();\n",
    "\n",
    "from hyperparameters import Hyperparameters\n",
    "from datamodules import ImagenetteDataLoader, viz_batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IMAGENET = Path(\"/mnt/c/Users/SambhavChandra/datasets/imagenet/\")\n",
    "IMAGENET = Path(\"/run/media/sambhav/2A2E24A52E246BCF/Users/SambhavChandra/datasets/imagenet/\") \n",
    "#IMAGENET_SHARDS = Path.home() / \"datasets\" / \"imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def viz_batch(batch: tuple[torch.Tensor, torch.Tensor], le: LabelEncoder) -> None:\n",
    "    images, targets = batch\n",
    "    labels = le.inverse_transform(targets.ravel())\n",
    "    assert images.shape[0] == targets.shape[0], \"#images != #targets\"\n",
    "\n",
    "    subplot_dims:tuple[int, int]\n",
    "    if images.shape[0] <= 8:\n",
    "        subplot_dims = (1, images.shape[0])\n",
    "    else:\n",
    "        subplot_dims = (int(np.ceil(images.shape[0]/8)), 8)\n",
    "\n",
    "    figsize = 20\n",
    "    figsize_factor = subplot_dims[0] / subplot_dims[1]\n",
    "    _, axes = plt.subplots(nrows = subplot_dims[0], \n",
    "                           ncols = subplot_dims[1], \n",
    "                           figsize = (figsize, figsize * figsize_factor))\n",
    "    for idx, ax in enumerate(axes.ravel()):\n",
    "        ax.imshow(images[idx].permute(1, 2, 0))\n",
    "        ax.tick_params(axis = \"both\", which = \"both\", \n",
    "                       bottom = False, top = False, \n",
    "                       left = False, right = False,\n",
    "                       labeltop = False, labelbottom = False, \n",
    "                       labelleft = False, labelright = False)\n",
    "        ax.set_xlabel(f\"{labels[idx]}({targets[idx].item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataLoader(dp.iter.IterDataPipe):\n",
    "    def __init__(self, \n",
    "                 src_dp: dp.iter.IterDataPipe, \n",
    "                 label_encoder: LabelEncoder,\n",
    "                 transform: Callable | None = None):\n",
    "        self.src_dp  = src_dp \n",
    "        assert label_encoder\n",
    "        self.le = label_encoder\n",
    "        self.transform = transform if transform else self._default_transform\n",
    "    \n",
    "    def __iter__(self): \n",
    "        for path, label in self.src_dp:\n",
    "           yield (self.transform(self._load_image(path)),\n",
    "                  self._encode_label(label))\n",
    "     \n",
    "    def _load_image(self, image_path: Path) -> torch.Tensor:\n",
    "        image = (iio.imread(uri = image_path,\n",
    "                           plugin = \"pillow\",\n",
    "                           extension = \".jpeg\")\n",
    "                    .squeeze())\n",
    "        #Duplicate Grayscale Image\n",
    "        if image.ndim == 2:\n",
    "            image = np.stack((image,)*3, axis = -1)\n",
    "        assert image.shape[-1] == 3\n",
    "        return torch.from_numpy(image.transpose(2, 0, 1))\n",
    "\n",
    "    def _encode_label(self, label) -> torch.Tensor:\n",
    "        return torch.from_numpy(\n",
    "            self.le.transform([label])\n",
    "        ).squeeze()\n",
    "    \n",
    "    def _default_transform(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        transform = t.Compose([\n",
    "            t.Resize((256, 256), antialias = True),\n",
    "            t.ConvertImageDtype(torch.float32)\n",
    "        ])\n",
    "        return transform(image / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImagenetRemoteDataset(StreamingDataset):\n",
    "    def __init__(self,\n",
    "                 remote: str,\n",
    "                 local: str,\n",
    "                 shuffle: bool,\n",
    "                 batch_size: int,\n",
    "                 cache_limit: int|str,\n",
    "                 shuffle_seed: int = 420,\n",
    "                 transform: Callable | None = None\n",
    "                ) -> None:\n",
    "        super().__init__(local=local, remote=remote, \n",
    "                         shuffle=shuffle, shuffle_seed=shuffle_seed,\n",
    "                         batch_size=batch_size, cache_limit=cache_limit\n",
    "                         )\n",
    "        self.transform = transform if transform else self._default_transform\n",
    "\n",
    "    def __getitem__(self, idx:int) -> Any:\n",
    "        obj = super().__getitem__(idx)\n",
    "        image = self._load_image(obj[\"image\"]) \n",
    "        label = torch.tensor(obj[\"label\"], dtype = torch.float32)\n",
    "\n",
    "        return self.transform(image), label\n",
    "\n",
    "    def _load_image(self, bytestream: bytes):\n",
    "        image = (iio.imread(uri = bytestream,\n",
    "                           plugin = \"pillow\",\n",
    "                           extension = \".jpg\")\n",
    "                    .squeeze())\n",
    "        #Duplicate Grayscale Image\n",
    "        if image.ndim == 2:\n",
    "            image = np.stack((image,)*3, axis = -1)\n",
    "        assert image.shape[-1] == 3\n",
    "        return torch.from_numpy(image.transpose(2, 0, 1))\n",
    "    \n",
    "    def _default_transform(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        transform = t.Compose([\n",
    "            t.Resize((256, 256), antialias = True),\n",
    "            t.ConvertImageDtype(torch.float32)\n",
    "        ])\n",
    "        return transform(image / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImagenetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, root: Path, params: Hyperparameters, remote: str | None = None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.remote = remote\n",
    "        if remote is not None:\n",
    "            self._setup_remote()\n",
    "        else:\n",
    "            self._setup_local()\n",
    "\n",
    "        self.params = params\n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            if self.remote is not None:\n",
    "                self.train_dataset = self._prepare_remote_train()\n",
    "            else:\n",
    "                self.train_dataset = self._prepare_local_train()\n",
    "\n",
    "        elif stage == \"test\":\n",
    "            if self.remote is not None:\n",
    "                self.val_dataset = self._prepare_remote_val()\n",
    "            else:\n",
    "                self.val_dataset = self._prepare_local_val()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset = self.train_dataset, \n",
    "            batch_size = self.params.batch_size,\n",
    "            num_workers = self.params.num_workers,\n",
    "            #shuffle = True\n",
    "            )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset = self.val_dataset, \n",
    "            batch_size = self.params.batch_size,\n",
    "            num_workers = self.params.num_workers,\n",
    "            )\n",
    "    \n",
    "    def _setup_local(self) -> None:\n",
    "        labels = self.root / \"LOC_synset_mapping.txt\"\n",
    "        self.labels_df = self._get_labels_df(labels)\n",
    "        self._prepare_label_encoder(sorted(self.labels_df.index.tolist()))\n",
    "\n",
    "        train_dir = self.root / \"ILSVRC\" / \"Data\" / \"CLS-LOC\" / \"train\"\n",
    "        val_soln = self.root / \"LOC_val_solution.csv\"\n",
    "\n",
    "        self.train_df = self._get_train_df(train_dir, Path.cwd() / \"train.csv\")\n",
    "        self.val_df = self._get_val_df(val_soln, Path.cwd() / \"val.csv\")\n",
    "    \n",
    "    def _setup_remote(self) -> None:\n",
    "        #TODO: how to handle label_encoder creation? hardcode class names? or put labels.csv on remote?\n",
    "        self.labels_df = pd.read_csv(Path.cwd() / \"labels.csv\", index_col=0) \n",
    "        self._prepare_label_encoder(sorted(self.labels_df.index.tolist()))\n",
    "\n",
    "        self.local_shards_train: Path = self.root / \"shards\" / \"train\"\n",
    "        self._reset_dir(self.local_shards_train)\n",
    "\n",
    "        self.local_shards_val: Path = self.root / \"shards\" / \"val\"\n",
    "        self._reset_dir(self.local_shards_val)\n",
    "\n",
    "        self.remote_shards_train: str = self.remote + \"/train\"\n",
    "        self.remote_shards_val: str = self.remote + \"/val\"\n",
    "\n",
    "        clean_stale_shared_memory()\n",
    "\n",
    "    def _prepare_local_train(self) -> Any:\n",
    "            datapipe = self._datapipe_from_dataframe(self.train_df)\n",
    "            #Sharding Filter, Prefetcher, Pinned Memory\n",
    "            #self.train_dp = (self.train_dp\n",
    "                                #.shuffle(buffer_size=len(self.train_df)))\n",
    "            datapipe = ImageDataLoader(datapipe, self.label_encoder) #type: ignore \n",
    "            datapipe = datapipe.set_length(len(self.train_df))\n",
    "            return datapipe\n",
    "    \n",
    "    def _prepare_local_val(self) -> Any:\n",
    "            datapipe = self._datapipe_from_dataframe(self.val_df)\n",
    "            datapipe = ImageDataLoader(datapipe, self.label_encoder) #type: ignore\n",
    "            datapipe = datapipe.set_length(len(self.val_df))\n",
    "            return datapipe\n",
    "\n",
    "    def _prepare_remote_train(self) -> Any:\n",
    "        clean_stale_shared_memory()\n",
    "        dataset = ImagenetRemoteDataset(\n",
    "            remote = self.remote_shards_train,\n",
    "            local = self.local_shards_train.as_posix(),\n",
    "            shuffle = False,\n",
    "            shuffle_seed = self.params.random_seed,\n",
    "            batch_size = self.params.batch_size,\n",
    "            cache_limit = self.params.local_cache_limit,\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    def _prepare_remote_val(self) -> Any:\n",
    "        clean_stale_shared_memory()\n",
    "        dataset = ImagenetRemoteDataset(\n",
    "            remote = self.remote_shards_val,\n",
    "            local = self.local_shards_val.as_posix(),\n",
    "            shuffle = False,\n",
    "            batch_size = self.params.batch_size,\n",
    "            cache_limit = self.params.local_cache_limit,\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    def _get_labels_df(self, path: Path) -> pd.DataFrame:\n",
    "        df = pd.read_table(path, header = None)\n",
    "        df = df[0].str.split(\" \", n = 2, expand = True)\n",
    "        df.columns = [\"wnid\", \"label\", \"words\"]\n",
    "        df[\"label\"] = df[\"label\"].str.strip(',')\n",
    "        df = df.set_index(\"wnid\")\n",
    "        return df \n",
    "\n",
    "    def _get_train_df(self, train_dir: Path, path_to_csv: Path | None = None) -> pd.DataFrame:\n",
    "        if path_to_csv:\n",
    "            assert path_to_csv.exists() and path_to_csv.is_file(), \"invalid path\" #type: ignore\n",
    "\n",
    "            df = pd.read_csv(path_to_csv, index_col=0)\n",
    "            df[\"path\"] = df[\"path\"].apply(lambda x: train_dir / x)\n",
    "            return df[[\"path\", \"label\"]] #type: ignore\n",
    "\n",
    "        else:\n",
    "            df = pd.DataFrame({\"path\": list(train_dir.rglob(\"*.JPEG\"))})\n",
    "            df[\"label\"] = df[\"path\"].apply(lambda x: x.parent.stem)\n",
    "            return df\n",
    "\n",
    "    def _get_val_df(self, val_soln_csv: Path | None = None, val_csv: Path | None = None) -> pd.DataFrame:\n",
    "        val_prefix: Path = self.root / \"ILSVRC\" / \"Data\" / \"CLS-LOC\" / \"val\"\n",
    "        if val_csv:\n",
    "            assert val_csv.exists() and val_csv.is_file(), \"invalid path\"\n",
    "            df = pd.read_csv(val_csv, index_col=0)\n",
    "\n",
    "            df[\"path\"] = df[\"path\"].apply(lambda x: val_prefix / x)\n",
    "            return df[[\"path\", \"label\"]] #type: ignore\n",
    "\n",
    "        elif val_soln_csv:\n",
    "            assert val_soln_csv.exists() and val_soln_csv.is_file(), \"invalid soln path\"\n",
    "\n",
    "            df = pd.read_csv(val_soln_csv) \n",
    "            df[\"path\"] = df[\"ImageId\"].apply(lambda x: val_prefix / f\"{x}.JPEG\") #type: ignore\n",
    "            df[\"label\"] = df[\"PredictionString\"].str.split(\" \", n = 1, expand = True).iloc[:, 0]\n",
    "            return df[[\"path\", \"label\"]] #type: ignore\n",
    "        \n",
    "    def _datapipe_from_dataframe(self, dataframe: pd.DataFrame):\n",
    "        return dp.iter.Zipper(\n",
    "            dp.iter.IterableWrapper(dataframe.path),\n",
    "            dp.iter.IterableWrapper(dataframe.label)\n",
    "            )\n",
    "    \n",
    "    def _prepare_label_encoder(self, class_names: list):\n",
    "        self.label_encoder = LabelEncoder().fit(class_names)\n",
    "    \n",
    "    def _reset_dir(self, dir_path: Path) -> None:\n",
    "        if dir_path.exists() and dir_path.is_dir():\n",
    "            shutil.rmtree(dir_path)\n",
    "        dir_path.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, model, params: Hyperparameters):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.model = model\n",
    "        \n",
    "        self._set_metrics()\n",
    "        self.save_hyperparameters(\n",
    "            {i:params.get_dict()[i] for i in params.get_dict().keys() if i!='criterion'},\n",
    "            ignore = [\"model\"]\n",
    "        ) \n",
    "    \n",
    "    def forward(self, batch):\n",
    "        x, _ = batch\n",
    "        return self.model(x)\n",
    "\n",
    "    def _set_metrics(self):\n",
    "        self.train_metrics = torchmetrics.Accuracy(\"multiclass\", \n",
    "                                    num_classes=self.params.num_classes,\n",
    "                                    average = \"micro\")\n",
    "        self.test_metrics = torchmetrics.Accuracy(\"multiclass\",\n",
    "                                    num_classes=self.params.num_classes, \n",
    "                                    average = \"micro\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch, self.train_metrics)\n",
    "        self.log(\"train_loss\", loss, on_step = True, on_epoch = True)\n",
    "        #self.log_dict(self.train_metrics, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._forward_pass(batch, self.test_metrics)\n",
    "        self.log(\"test_loss\", loss)\n",
    "    \n",
    "    #def validation_step(self, batch, batch_idx):\n",
    "        #loss = self._forward_pass(batch, self.val_metrics)\n",
    "        #self.log(\"val_loss\", loss)\n",
    "      \n",
    "    def configure_optimizers(self):\n",
    "        return self.params.optimizer(self.model.parameters(), \n",
    "                                     lr = self.params.learning_rate)\n",
    "\n",
    "    def _forward_pass(self, batch, metrics):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        #metrics(y_pred, y) \n",
    "        return self.params.criterion(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "experiment = Hyperparameters(\n",
    "    task = \"multiclass_classification\",\n",
    "    random_seed = 42,\n",
    "    num_classes = 1000,\n",
    "    test_split = .3,\n",
    "    metrics = [\"accuracy\", \"f1score\"],\n",
    "\n",
    "    learning_rate = 1e-6,\n",
    "    batch_size =  64,\n",
    "    num_workers = 16,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    criterion = torch.nn.CrossEntropyLoss(),\n",
    "\n",
    "    local_cache_limit = \"10gb\"\n",
    ")\n",
    "\n",
    "pl.seed_everything(experiment.random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagenet = ImagenetDataModule(IMAGENET, experiment)\n",
    "alexnet = AlexNet(experiment.num_classes)\n",
    "classifier = ClassificationModel(alexnet, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sambhav/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataLoader' object has no attribute '_standard_transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      2\u001b[0m     fast_dev_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model \u001b[38;5;241m=\u001b[39m classifier, datamodule \u001b[38;5;241m=\u001b[39m imagenet)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:941\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39msetup_environment()\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setup_profiler()\n\u001b[0;32m--> 941\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_setup_hook(\u001b[38;5;28mself\u001b[39m)  \u001b[38;5;66;03m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:85\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     82\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_setup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mdatamodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     _call_lightning_datamodule_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n\u001b[1;32m     86\u001b[0m _call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n\u001b[1;32m     87\u001b[0m _call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:166\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mImagenetDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_remote_train()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_local_train()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[6], line 73\u001b[0m, in \u001b[0;36mImagenetDataModule._prepare_local_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m datapipe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapipe_from_dataframe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#Sharding Filter, Prefetcher, Pinned Memory\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#self.train_dp = (self.train_dp\u001b[39;00m\n\u001b[1;32m     72\u001b[0m                     \u001b[38;5;66;03m#.shuffle(buffer_size=len(self.train_df)))\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m datapipe \u001b[38;5;241m=\u001b[39m ImageDataLoader(datapipe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoder) \u001b[38;5;66;03m#type: ignore \u001b[39;00m\n\u001b[1;32m     74\u001b[0m datapipe \u001b[38;5;241m=\u001b[39m datapipe\u001b[38;5;241m.\u001b[39mset_length(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datapipe\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mImageDataLoader.__init__\u001b[0;34m(self, src_dp, label_encoder, transform)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m label_encoder\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle \u001b[38;5;241m=\u001b[39m label_encoder\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_standard_transform\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.11/site-packages/torch/utils/data/datapipes/datapipe.py:127\u001b[0m, in \u001b[0;36mIterDataPipe.__getattr__\u001b[0;34m(self, attribute_name)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, attribute_name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageDataLoader' object has no attribute '_standard_transform"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=True\n",
    ")\n",
    "trainer.fit(model = classifier, datamodule = imagenet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
