{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "\n",
    "%autoreload 2\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Modules\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# General Purpose Libraries \n",
    "import torch\n",
    "import wandb\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import imageio.v3 as iio\n",
    "\n",
    "# Paths, Datasets and Datamodules\n",
    "from etl.pathfactory import PathFactory\n",
    "from etl.etl import reset_dir\n",
    "from data.datamodules import ImageDatasetDataModule \n",
    "from datasets.imagenette import ImagenetteClassification\n",
    "\n",
    "# Transforms\n",
    "import torchvision.transforms.v2 as t\n",
    "\n",
    "# Models\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "\n",
    "# Tasks\n",
    "from training.tasks import ClassificationTask\n",
    "from training.callbacks import ClassificationReport \n",
    "from training.callbacks import setup_logger, setup_wandb_logger, setup_checkpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "#Trainers\n",
    "from lightning import Trainer\n",
    "\n",
    "# Type Hints\n",
    "from typing import Callable, Any, Optional, Literal\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "from lightning.pytorch.utilities import disable_possible_user_warnings # type: ignore\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
    "disable_possible_user_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"experiments.ipynb\" \n",
    "experiment = {\n",
    "    \"name\": \"test_run\",\n",
    "\n",
    "    \"dataset_name\": \"imagenette\",\n",
    "    \"model_name\": \"alexnet-pretrained\",\n",
    "    \"task\": \"classification\",\n",
    "    \"num_classes\": 10,\n",
    "    \"class_names\": ImagenetteClassification.CLASS_NAMES,\n",
    "\n",
    "    \"random_seed\": 69,\n",
    "\n",
    "    \"test_split\": 0.2,\n",
    "    \"val_split\": 0.2,\n",
    "    \"batch_size\": 32,\n",
    "    \"grad_accum\": 1,\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"loss\": \"cross_entropy\",\n",
    "    \"loss_params\": {\n",
    "        \"reduction\": \"mean\",\n",
    "    },\n",
    "\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": 5e-6,\n",
    "    },\n",
    "\n",
    "    \"monitor_metric\": \"accuracy\",\n",
    "    \"monitor_mode\": \"max\",\n",
    "}\n",
    "PATHS = PathFactory(experiment[\"dataset_name\"], experiment[\"task\"])\n",
    "\n",
    "image_transform = t.Compose([\n",
    "    t.ToImage(),\n",
    "    t.ToDtype(torch.float32, scale=True),\n",
    "    t.Normalize(ImagenetteClassification.MEANS, ImagenetteClassification.STD_DEVS),\n",
    "    t.Resize((224, 224), antialias=True),\n",
    "    t.RandomHorizontalFlip(0.5),\n",
    "])\n",
    "\n",
    "datamodule = ImageDatasetDataModule(\n",
    "    root = PATHS.path,\n",
    "    is_remote = False,\n",
    "    is_streaming = False,\n",
    "    dataset_constructor = ImagenetteClassification, \n",
    "    image_transform = image_transform,\n",
    "    **experiment\n",
    ")\n",
    "display(datamodule)\n",
    "\n",
    "alexnet_p = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "alexnet_p.classifier[-1] = torch.nn.Linear(4096, experiment.get(\"num_classes\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger(PATHS.experiments_path, experiment[\"name\"])\n",
    "reset_dir(logger.log_dir)\n",
    "wandb_logger = setup_wandb_logger(PATHS.experiments_path, experiment[\"name\"])\n",
    "checkpoint = setup_checkpoint(Path(logger.log_dir, \"model_ckpts\"), experiment[\"monitor_metric\"], experiment[\"monitor_mode\"]) \n",
    "classification_report = ClassificationReport()\n",
    "\n",
    "BEST_CKPT = checkpoint.best_model_path \n",
    "LAST_CKPT = checkpoint.last_model_path\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint, classification_report],\n",
    "    logger = [logger, wandb_logger],\n",
    "    enable_model_summary=False,\n",
    "    #num_sanity_val_steps=0,\n",
    "\n",
    "    max_epochs=8,\n",
    "    check_val_every_n_epoch=2, \n",
    "    #limit_train_batches=10,\n",
    "    #limit_val_batches=10,\n",
    "    #limit_test_batches=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=ClassificationTask(alexnet_p, **experiment),\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path= LAST_CKPT if Path(LAST_CKPT).is_file() else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(\n",
    "    model=ClassificationTask(alexnet_p, **experiment),\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path=LAST_CKPT if Path(LAST_CKPT).is_file() else None,\n",
    "    verbose = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
