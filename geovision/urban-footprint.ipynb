{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "\n",
    "%autoreload 2\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\");\n",
    "\n",
    "## System Modules\n",
    "from pathlib import Path\n",
    "\n",
    "## General Purpose Libraries \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Paths and Directory Management\n",
    "from etl.pathfactory import PathFactory\n",
    "from etl.etl import reset_dir\n",
    "\n",
    "## Datasets and Datamodules\n",
    "from data.datamodules import ImageDatasetDataModule \n",
    "from datasets.inria import InriaBase, InriaImageFolder, InriaStreaming, InriaHDF5 \n",
    "\n",
    "## Transforms\n",
    "import torchvision.transforms.v2 as t\n",
    "\n",
    "## Tasks\n",
    "from training.tasks import SegmentationTask \n",
    "\n",
    "## Loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger, CSVLogger\n",
    "from lightning import seed_everything\n",
    "\n",
    "##Trainers\n",
    "from lightning import Trainer\n",
    "\n",
    "#Types\n",
    "from typing import Literal\n",
    "\n",
    "from datasets.test import test_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Val Test Splits\n",
    "# 1. Random Split: Each location will be split based on the test_split and val_split parameters\n",
    "# 2. Continental Split: Train on Europe, Test on NA or Vice Versa \n",
    "# 3. Cultural Split: Train on Developed Locations Like Paris, Chicago and Zurich and Test on Rawanda, Kenya and Rio  \n",
    "# 4. Unsupervised Split: Unsupervised Training on Inria-Test and Finetune on Inria-Train (with varying fractions of training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_DIR = Path.cwd() / \"logs\"\n",
    "CHECKPOINTS_DIR = LOGS_DIR / \"checkpoints\"\n",
    "reset_dir(LOGS_DIR)\n",
    "reset_dir(CHECKPOINTS_DIR)\n",
    "\n",
    "def setup_checkpoint(\n",
    "        ckpt_dir: Path,\n",
    "        metric: str,\n",
    "        mode: Literal[\"min\", \"max\"],\n",
    "    ) -> ModelCheckpoint:\n",
    "    return ModelCheckpoint(\n",
    "        dirpath = ckpt_dir,\n",
    "        monitor = metric,\n",
    "        mode = mode,\n",
    "        filename = \"{epoch}-{\" + metric + \":.2f}\",\n",
    "        save_top_k = 1,\n",
    "        save_last = True,\n",
    "        save_on_train_epoch_end = True)\n",
    "\n",
    "def setup_logger(\n",
    "        logs_dir: Path,\n",
    "        name: str,\n",
    "        version: int\n",
    "    ):\n",
    "    return CSVLogger(\n",
    "        save_dir=logs_dir,\n",
    "        name=name,\n",
    "        version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = {\n",
    "    \"dataset_name\": \"urban-footprint\",\n",
    "    \"task\": \"segmentation\",\n",
    "    \"random_seed\": 69,\n",
    "    \"tile_size\": (512, 512),\n",
    "    \"tile_stride\": (512, 512),\n",
    "\n",
    "    \"val_split\": 0.2,\n",
    "    \"test_split\": 0.2,\n",
    "    \"batch_size\": 4,\n",
    "    \"grad_accum\": 1,\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"num_classes\": 2,\n",
    "    \"loss\": \"binary_cross_entropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-5,\n",
    "\n",
    "    \"checkpoint_metric\": \"val_macro_precision\",\n",
    "    \"checkpoint_mode\": \"max\"\n",
    "}\n",
    "seed_everything(experiment[\"random_seed\"]);\n",
    "\n",
    "model_ckpt = setup_checkpoint(\n",
    "    CHECKPOINTS_DIR,\n",
    "    experiment[\"checkpoint_metric\"],\n",
    "    experiment[\"checkpoint_mode\"]\n",
    ")\n",
    "\n",
    "logger = setup_logger(\n",
    "    LOGS_DIR,\n",
    "    experiment[\"dataset_name\"] + '-' + experiment[\"task\"],\n",
    "    version = 1 \n",
    ")\n",
    "\n",
    "paths = PathFactory(experiment[\"dataset_name\"], experiment[\"task\"])\n",
    "\n",
    "image_transform = t.Compose([\n",
    "    t.ToImage(),\n",
    "    t.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "mask_transform = t.Compose([\n",
    "    t.ToImage(),\n",
    "    t.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "augmentations = t.Compose([\n",
    "    t.Identity()\n",
    "])\n",
    "\n",
    "datamodule = ImageDatasetDataModule(\n",
    "    root = paths.path,\n",
    "    is_remote = False,\n",
    "    is_streaming = False,\n",
    "    dataset_constructor = InriaHDF5, \n",
    "    image_transform = image_transform,\n",
    "    target_transform = mask_transform,\n",
    "    common_transform = augmentations,\n",
    "    **experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.models import FCN\n",
    "model = FCN(\n",
    "    in_channels = 3,\n",
    "    classes = 2,\n",
    "    num_filters = 32 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ckpt_path = (CHECKPOINTS_DIR / \"last.ckpt\").as_posix() if (CHECKPOINTS_DIR / \"last.ckpt\").is_file() else None\n",
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=model_ckpt,\n",
    "    max_epochs=10,\n",
    "    check_val_every_n_epoch=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model = SegmentationTask(model, **experiment),\n",
    "    datamodule = datamodule,\n",
    "    ckpt_path = last_ckpt_path \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(\n",
    "    model = SegmentationTask(model, **experiment),\n",
    "    datamodule = datamodule,\n",
    "    ckpt_path = last_ckpt_path \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
