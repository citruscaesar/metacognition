{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "%dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms.v2 as t\n",
    "from lightning import Trainer\n",
    "\n",
    "import sys; sys.path.append(\"../\") if \"../\" not in sys.path else None\n",
    "\n",
    "from datasets.datamodules import ImageDatasetDataModule \n",
    "\n",
    "from training.tasks import ClassificationTask\n",
    "from training.callbacks import (\n",
    "    setup_logger, setup_wandb_logger, setup_checkpoint, eval_callback\n",
    ")\n",
    "\n",
    "from etl.pathfactory import PathFactory\n",
    "from etl.etl import reset_dir\n",
    "from viz.dataset_plots import plot_segmentation_samples\n",
    "\n",
    "import logging\n",
    "from lightning.pytorch.utilities import disable_possible_user_warnings # type: ignore\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
    "disable_possible_user_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scene dataset @ [/home/sambhav/shards/urban_footprint/train]\n"
     ]
    }
   ],
   "source": [
    "#from datasets.inria_speedtest import InriaImageFolder, InriaHDF5\n",
    "from datasets.inria_speedtest import InriaLitData, InriaSegmentation\n",
    "from pandas import DataFrame\n",
    "from typing import Literal, Optional\n",
    "from torchvision.transforms.v2 import Transform\n",
    "\n",
    "inria_kwargs = {\n",
    "    #\"root\" : Path.home() / \"datasets\" / \"urban_footprint\",\n",
    "    #\"shards\": Path.home() / \"shards\" / \"urban_footprint\",\n",
    "    \"root\": Path.home() / \"shards\" / \"urban_footprint\",\n",
    "    \"test_split\": 0.2, \"val_split\": 0.2, \"random_seed\": 69,\n",
    "    \"tile_size\": (512, 512), \"tile_stride\": (512, 512),\n",
    "    \"split\": \"train\",\n",
    "    \"shard_size_in_mb\": 256 \n",
    "}\n",
    "#InriaSegmentation.write_to_litdata(**inria_kwargs)\n",
    "ds = InriaLitData(**inria_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_segmentation_samples(ds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from segmentation_models_pytorch import Unet\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets.inria_speedtest import InriaImageFolder, InriaLitData, InriaHDF5\n",
    "\n",
    "inria_kwargs = {\n",
    "    \"root\" : Path.home() / \"datasets\" / \"urban_footprint\", \n",
    "    #\"root\": Path.home() / \"shards\" / \"urban_footprint\",\n",
    "    \"split\": \"train\",\n",
    "    \"shuffle\": True,\n",
    "    \"test_split\": 0.2, \"val_split\": 0.2, \"random_seed\": 69,\n",
    "    \"tile_size\": (512, 512), \"tile_stride\": (512, 512)\n",
    "}\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset = InriaHDF5(**inria_kwargs), \n",
    "    batch_size = 2, num_workers=4, \n",
    "    pin_memory = True,  prefetch_factor = 10 \n",
    ")\n",
    "unet = Unet(\"resnet18\", classes=2, encoder_weights=\"imagenet\") \n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "adam = torch.optim.Adam(unet.parameters(), lr = 1e-5)\n",
    "\n",
    "def train_one_epoch(dataloader: DataLoader, model: Module, criterion: Module, optimizer: Optimizer, limit_train_batches: Optional[int] = None):\n",
    "    if limit_train_batches is None:\n",
    "        limit_train_batches = len(dataloader)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for idx, batch in tqdm(enumerate(dataloader), total = limit_train_batches, unit = \"steps\"):\n",
    "        if idx >= limit_train_batches:\n",
    "            break\n",
    "            \n",
    "        images, masks = batch[0].to(device), batch[1].to(device)\n",
    "        preds = model(images) \n",
    "        loss = criterion(preds.argmax(1).to(torch.float32), masks.argmax(1).to(torch.float32)).mean()\n",
    "        loss.requires_grad_()\n",
    "        #print(f\"Step: {idx}, Loss: {loss}\")\n",
    "        #print(images.shape, images.dtype, images.min().item(), images.max().item())\n",
    "        #print(masks.shape, masks.dtype, masks.min().item(), masks.max().item())\n",
    "        #print(preds.shape, preds.dtype, preds.min().item(), preds.max().item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train_one_epoch(dl, unet, loss_fn, adam, 500)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = InriaHDF5 \n",
    "# MODEL = Unet\n",
    "experiment = {\n",
    "    \"name\": \"test_run\",\n",
    "    \"model_name\": \"unet\",\n",
    "    \"model_params\": {\n",
    "        \"encoder\": \"resnet18\",\n",
    "        \"decoder\": \"deconvolution\",\n",
    "        \"weights\": \"imagenet\",\n",
    "    },\n",
    "\n",
    "    \"dataset_name\": DATASET.NAME,\n",
    "    \"task\": DATASET.TASK,\n",
    "    \"num_classes\": DATASET.NUM_CLASSES,\n",
    "    \"class_names\": DATASET.CLASS_NAMES,\n",
    "\n",
    "    \"random_seed\": 69,\n",
    "\n",
    "    \"test_split\": 0.2,\n",
    "    \"val_split\": 0.2,\n",
    "    \"batch_size\": 4,\n",
    "    \"grad_accum\": 1,\n",
    "    \"num_workers\": 4,\n",
    "\n",
    "    \"loss\": \"cross_entropy\",\n",
    "    \"loss_params\": {\n",
    "        \"reduction\": \"mean\",\n",
    "    },\n",
    "\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": 1e-5,\n",
    "    },\n",
    "\n",
    "    \"monitor_metric\": \"iou\",\n",
    "    \"monitor_mode\": \"max\",\n",
    "\n",
    "    \"tile_size\": (512, 512),\n",
    "    \"tile_stride\": (512, 512),\n",
    "}\n",
    "PATHS = PathFactory(experiment[\"dataset_name\"], experiment[\"task\"])\n",
    "LOGS_DIR = PATHS.experiments_path / experiment[\"name\"]\n",
    "\n",
    "# NOTE: t.Normalize(DATASET.MEANS, DATASET.STD_DEVS),\n",
    "image_transform = t.Compose([t.ToImage(), t.ToDtype(torch.float32, scale=True)])\n",
    "mask_transform = t.Compose([t.ToImage(), t.ToDtype(torch.float32, scale=False)])\n",
    "#augmentations = t.Compose([t.RandomHorizontalFlip(0.5))\n",
    "augmentations = None\n",
    "\n",
    "datamodule = ImageDatasetDataModule(\n",
    "    root = PATHS.path,\n",
    "    is_remote = False,\n",
    "    is_streaming = False,\n",
    "    dataset_constructor = DATASET, \n",
    "    image_transform = image_transform,\n",
    "    target_transform = mask_transform,\n",
    "    common_transform = augmentations,\n",
    "    **experiment\n",
    ")\n",
    "display(datamodule)\n",
    "logger = setup_logger(PATHS.experiments_path, experiment[\"name\"])\n",
    "wandb_logger = setup_wandb_logger(PATHS.experiments_path, experiment[\"name\"])\n",
    "checkpoint = setup_checkpoint(Path(logger.log_dir, \"model_ckpts\"), experiment[\"monitor_metric\"], experiment[\"monitor_mode\"], \"all\") \n",
    "reset_dir(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "#from torchvision.models import resnet18, ResNet18_Weights\n",
    "#model = resnet18(weights = ResNet18_Weights.DEFAULT)\n",
    "#model.fc = torch.nn.Linear(512, experiment[\"num_classes\"])\n",
    "\n",
    "#from torchvision.models import alexnet, AlexNet_Weights\n",
    "#model = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "#model = alexnet(weights=None)\n",
    "#model.classifier[-1] = torch.nn.Linear(4096, experiment.get(\"num_classes\", 10))\n",
    "\n",
    "from segmentation_models_pytorch import Unet\n",
    "model = Unet(experiment[\"model_params\"][\"encoder\"], classes=experiment[\"num_classes\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_CKPT = checkpoint.best_model_path \n",
    "LAST_CKPT = checkpoint.last_model_path\n",
    "evaluation = eval_callback(experiment[\"task\"])\n",
    "trainer = Trainer(\n",
    "    #callbacks=[checkpoint],\n",
    "    enable_checkpointing=False,\n",
    "    logger = [logger],\n",
    "    enable_model_summary=False,\n",
    "    #fast_dev_run=True,\n",
    "    num_sanity_val_steps=0,\n",
    "    max_epochs=1,\n",
    "    #check_val_every_n_epoch=3, \n",
    "    #limit_train_batches=100,\n",
    "    #limit_val_batches=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#experiment[\"optimizer_params\"][\"lr\"] =  5e-6 \n",
    "trainer.fit(\n",
    "    model=ClassificationTask(model, **experiment),\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path=LAST_CKPT if Path(LAST_CKPT).is_file() else None,\n",
    "    #verbose=False\n",
    ")\n",
    "\n",
    "#trainer.test(\n",
    "    #model=ClassificationTask(model, **experiment),\n",
    "    #datamodule=datamodule,\n",
    "    #ckpt_path=LAST_CKPT if Path(LAST_CKPT).is_file() else None,\n",
    "    #verbose = False\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.evaluation import checkpoints_df, plot_checkpoints, plot_checkpoint_attribution\n",
    "\n",
    "plot_checkpoints(LOGS_DIR, experiment[\"monitor_metric\"], checkpoints_df(LOGS_DIR, experiment[\"monitor_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 11 \n",
    "step = 3024 \n",
    "split = \"best\"\n",
    "k = 25 \n",
    "plot_checkpoint_attribution(model, LOGS_DIR, PATHS.path, DATASET, epoch, step, split, k, **experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
