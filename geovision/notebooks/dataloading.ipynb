{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "%autoreload 2\n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2 as t\n",
    "from typing import Callable, Optional, Literal, Any\n",
    "\n",
    "import sys; sys.path.append(\"../\") if \"../\" not in sys.path else None\n",
    "from viz.dataset_plots import plot_segmentation_samples\n",
    "\n",
    "import logging\n",
    "from lightning.pytorch.utilities import disable_possible_user_warnings # type: ignore\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
    "disable_possible_user_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tiled dataset @ [C:\\Users\\SambhavChandra\\datasets\\urban_footprint\\inria.h5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_idx</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>tile_name</th>\n",
       "      <th>split</th>\n",
       "      <th>hbeg</th>\n",
       "      <th>hend</th>\n",
       "      <th>wbeg</th>\n",
       "      <th>wend</th>\n",
       "      <th>df_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>austin1.tif</td>\n",
       "      <td>austin1_0_512_0_512.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>austin1.tif</td>\n",
       "      <td>austin1_0_512_512_1024.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>austin1.tif</td>\n",
       "      <td>austin1_0_512_1024_1536.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>1536</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>austin1.tif</td>\n",
       "      <td>austin1_0_512_1536_2048.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>1536</td>\n",
       "      <td>2048</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>austin1.tif</td>\n",
       "      <td>austin1_0_512_2048_2560.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>2560</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>179</td>\n",
       "      <td>tyrol-w36.tif</td>\n",
       "      <td>tyrol-w36_4608_5120_2560_3072.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>4608</td>\n",
       "      <td>5120</td>\n",
       "      <td>2560</td>\n",
       "      <td>3072</td>\n",
       "      <td>17995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>179</td>\n",
       "      <td>tyrol-w36.tif</td>\n",
       "      <td>tyrol-w36_4608_5120_3072_3584.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>4608</td>\n",
       "      <td>5120</td>\n",
       "      <td>3072</td>\n",
       "      <td>3584</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>179</td>\n",
       "      <td>tyrol-w36.tif</td>\n",
       "      <td>tyrol-w36_4608_5120_3584_4096.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>4608</td>\n",
       "      <td>5120</td>\n",
       "      <td>3584</td>\n",
       "      <td>4096</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>179</td>\n",
       "      <td>tyrol-w36.tif</td>\n",
       "      <td>tyrol-w36_4608_5120_4096_4608.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>4608</td>\n",
       "      <td>5120</td>\n",
       "      <td>4096</td>\n",
       "      <td>4608</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>179</td>\n",
       "      <td>tyrol-w36.tif</td>\n",
       "      <td>tyrol-w36_4608_5120_4608_5120.tif</td>\n",
       "      <td>train</td>\n",
       "      <td>4608</td>\n",
       "      <td>5120</td>\n",
       "      <td>4608</td>\n",
       "      <td>5120</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       scene_idx     scene_name                          tile_name  split  \\\n",
       "0              0    austin1.tif            austin1_0_512_0_512.tif  train   \n",
       "1              0    austin1.tif         austin1_0_512_512_1024.tif  train   \n",
       "2              0    austin1.tif        austin1_0_512_1024_1536.tif  train   \n",
       "3              0    austin1.tif        austin1_0_512_1536_2048.tif  train   \n",
       "4              0    austin1.tif        austin1_0_512_2048_2560.tif  train   \n",
       "...          ...            ...                                ...    ...   \n",
       "12495        179  tyrol-w36.tif  tyrol-w36_4608_5120_2560_3072.tif  train   \n",
       "12496        179  tyrol-w36.tif  tyrol-w36_4608_5120_3072_3584.tif  train   \n",
       "12497        179  tyrol-w36.tif  tyrol-w36_4608_5120_3584_4096.tif  train   \n",
       "12498        179  tyrol-w36.tif  tyrol-w36_4608_5120_4096_4608.tif  train   \n",
       "12499        179  tyrol-w36.tif  tyrol-w36_4608_5120_4608_5120.tif  train   \n",
       "\n",
       "       hbeg  hend  wbeg  wend  df_idx  \n",
       "0         0   512     0   512       0  \n",
       "1         0   512   512  1024       1  \n",
       "2         0   512  1024  1536       2  \n",
       "3         0   512  1536  2048       3  \n",
       "4         0   512  2048  2560       4  \n",
       "...     ...   ...   ...   ...     ...  \n",
       "12495  4608  5120  2560  3072   17995  \n",
       "12496  4608  5120  3072  3584   17996  \n",
       "12497  4608  5120  3584  4096   17997  \n",
       "12498  4608  5120  4096  4608   17998  \n",
       "12499  4608  5120  4608  5120   17999  \n",
       "\n",
       "[12500 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets.inria import InriaLitData, InriaSegmentation, InriaHDF5, InriaImageFolder\n",
    "# import pandas as pd\n",
    "\n",
    "inria_kwargs = {\n",
    "    #\"root\" : Path.home() / \"datasets\" / \"urban_footprint\" / \"inria.h5\",\n",
    "    #\"shards\": Path.home() / \"shards\" / \"urban_footprint\",\n",
    "    \"test_split\": 0.2, \"val_split\": 0.1, \"random_seed\": 69,\n",
    "    \"tile_size\": (512, 512), \"tile_stride\": (512, 512),\n",
    "    ##\"shard_size_in_mb\": 256 \n",
    "}\n",
    "\n",
    "ds = InriaHDF5(\n",
    "    root = Path.home() / \"datasets\" / \"urban_footprint\" / \"inria.h5\",\n",
    "    split = \"train\",\n",
    "    **inria_kwargs,\n",
    ")\n",
    "\n",
    "display(ds.split_df)\n",
    "#train_df = InriaSegmentation.scene_df(**inria_kwargs)\n",
    "#train_df.assign(tile_name = lambda df: df.apply(lambda x: x.iloc[0]), axis = 0)\n",
    "#train_df = train_df[train_df[\"split\"] == \"train\"]\n",
    "#eval_df = InriaSegmentation.tiled_df(**inria_kwargs)\n",
    "#eval_df = eval_df[eval_df[\"split\"] != \"train\"]\n",
    "#dataset_df = pd.concat([train_df, eval_df], axis = 0)\n",
    "#dataset_df = dataset_df[dataset_df[\"split\"] != \"unsup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#InriaSegmentation.write_to_hdf(\n",
    "    #root = Path.home() / \"datasets\" / \"urban_footprint\",\n",
    "    #target = Path.home() / \"datasets\" / \"urban_footprint\" / \"file_write_test\",\n",
    "    #df = dataset_df\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_segmentation_samples(ds, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tiled dataset @ [C:\\Users\\SambhavChandra\\datasets\\urban_footprint\\inria.h5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad67b2c08ce47ef9b494b2febaec638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use Pytorch Profiler Here\n",
    "\n",
    "from segmentation_models_pytorch import Unet\n",
    "from datasets.inria import InriaImageFolder, InriaLitData, InriaHDF5\n",
    "\n",
    "inria_kwargs = {\n",
    "    \"root\" : Path.home() / \"datasets\" / \"urban_footprint\" / \"inria.h5\", \n",
    "    \"split\": \"train\",\n",
    "    \"test_split\": 0.2, \"val_split\": 0.1, \"random_seed\": 69,\n",
    "    \"tile_size\": (512, 512), \"tile_stride\": (512, 512)\n",
    "}\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset = InriaHDF5(**inria_kwargs), \n",
    "    batch_size = 2,\n",
    "    num_workers = 4, \n",
    "    #prefetch_factor = 10, \n",
    "    pin_memory = True, \n",
    "    shuffle = True,\n",
    "    persistent_workers = True\n",
    ")\n",
    "\n",
    "unet = Unet(\"resnet18\", classes=2, encoder_weights=\"imagenet\") \n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "adam = torch.optim.Adam(unet.parameters(), lr = 1e-5)\n",
    "\n",
    "def train_one_epoch(dataloader: DataLoader, model: Module, criterion: Module, optimizer: Optimizer, limit_train_batches: Optional[int] = None):\n",
    "    if limit_train_batches is None:\n",
    "        limit_train_batches = len(dataloader)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for idx, batch in tqdm(enumerate(dataloader), total = limit_train_batches, unit = \"steps\"):\n",
    "        if idx >= limit_train_batches:\n",
    "            break\n",
    "            \n",
    "        images, masks = batch[0].to(device), batch[1].to(device)\n",
    "        preds = model(images) \n",
    "        loss = criterion(preds.argmax(1).to(torch.float32), masks.argmax(1).to(torch.float32)).mean()\n",
    "        loss.requires_grad_()\n",
    "        #print(f\"Step: {idx}, Loss: {loss}\")\n",
    "        #print(images.shape, images.dtype, images.min().item(), images.max().item())\n",
    "        #print(masks.shape, masks.dtype, masks.min().item(), masks.max().item())\n",
    "        #print(preds.shape, preds.dtype, preds.min().item(), preds.max().item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train_one_epoch(dl, unet, loss_fn, adam, 500)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
