{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import imageio.v3 as iio\n",
    "import torchdata.datapipes as dp\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from hyperparameters import Hyperparameters\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv -o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path.home() / \"datasets\"\n",
    "RESISC = DATA_ROOT / \"resisc-45\" \n",
    "IMAGENET = DATA_ROOT / \"tiny-imagenet\"\n",
    "CIFAR10 = DATA_ROOT / \"cifar10\"\n",
    "MLRSNET = DATA_ROOT / \"mlrs-net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dp.functional_datapipe(\"load_image_label_pair\")\n",
    "class ImageLabelPairLoader(dp.iter.IterDataPipe):\n",
    "    def __init__(self, source_datapipe, label_encoder) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.label_encoder = label_encoder\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for file_name, file_stream in self.source_datapipe:\n",
    "            yield (self._load_image(file_stream), \n",
    "                   self._encode_label(file_name))\n",
    "\n",
    "    def _load_image(self, image_path: Path) -> torch.Tensor:\n",
    "        return torch.from_numpy(\n",
    "            iio.imread(uri = image_path, \n",
    "                       plugin = \"pillow\", \n",
    "                       extension = \".jpg\")\n",
    "                .astype(np.float32)\n",
    "                .transpose(2, 0, 1))\n",
    "\n",
    "    def _encode_label(self, file_name) -> torch.Tensor:\n",
    "        return torch.from_numpy(\n",
    "            self.label_encoder.transform([file_name.split(\"/\")[-2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection_kwargs = {\"endpoint_url\": \"https://usc1.contabostorage.com\"}\n",
    "#pipe = dp.iter.FSSpecFileLister(\"s3://resisc-45\", **connection_kwargs)\n",
    " ## type: ignore\n",
    "#class_names = sorted([Path(path).stem for path in iter(pipe)])\n",
    "#label_encoder = LabelEncoder().fit(class_names)\n",
    "\n",
    "#train_pipe, test_pipe = (dp.iter.FSSpecFileLister(pipe, **connection_kwargs)\n",
    "                                #.demux(2, train_test_split, buffer_size = 700 * 45))\n",
    "\n",
    "#train_pipe = (train_pipe.shuffle(buffer_size = 545 * 45)\n",
    "                        #.open_files_by_fsspec(\"rb\", **connection_kwargs) # type: ignore\n",
    "                        #.load_image_label_pair(label_encoder)\n",
    "             #)\n",
    "##train_pipe = ImageLabelPairLoader(train_pipe, label_encoder)\n",
    "\n",
    "#test_pipe = (test_pipe.open_files_by_fsspec(\"rb\", **connection_kwargs) # type: ignore\n",
    "                      #.load_image_label_pair(label_encoder)\n",
    "            #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dp.functional_datapipe(\"apply_image_transforms\")\n",
    "class ImageTransformer(dp.iter.IterDataPipe):\n",
    "    def __init__(self, source_datapipe, transforms = None) -> None:\n",
    "        self.source_datapipe = source_datapipe\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for image, annotation in self.source_datapipe:\n",
    "            if self.transforms is not None:\n",
    "                yield (self.transforms(image), annotation)\n",
    "            else:\n",
    "                yield (self._standard_transforms(image), annotation)\n",
    "                \n",
    "    def _standard_transforms(self, image: torch.Tensor):\n",
    "        return torchvision.transforms.Resize(256, antialias=True)(image / 255.0) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResiscDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, root: Path|str, is_s3_bucket: bool, params: Hyperparameters):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.params = params\n",
    "        self.is_s3_bucket = is_s3_bucket\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        self._remote_datapipe() if self.is_s3_bucket else self._local_datapipe()\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            #self.train_dp, self.val_dp = (\n",
    "                    #self.train_dp.random_split(weights={\"train\": (1-self.params.val_split), \"valid\": self.params.val_split}, \n",
    "                                               #total_length = 700 * self.params.num_classes,\n",
    "                                               #seed=self.params.random_seed)\n",
    "            #)\n",
    "            self.train_dp = dp.iter.Shuffler(self.train_dp, buffer_size = 700 * self.params.num_classes) #type: ignore\n",
    "            self.train_dp = ImageLabelPairLoader(self.train_dp, self.label_encoder)\n",
    "            self.train_dp = ImageTransformer(self.train_dp)\n",
    "            self.train_dp = self.train_dp.set_length(int(700 * (1-self.params.test_split) * self.params.num_classes))\n",
    "            #TODO: multiply len by (1-self.params.val_split) ?\n",
    "\n",
    "            #self.val_dp = ImageLabelPairLoader(self.val_dp, self.label_encoder)\n",
    "            #self.val_dp = ImageTransformer(self.val_dp)\n",
    "\n",
    "        if stage == \"test\":\n",
    "            self.test_dp = ImageLabelPairLoader(self.test_dp, self.label_encoder)\n",
    "            self.test_dp = ImageTransformer(self.test_dp)\n",
    "            self.test_dp = self.test_dp.set_length(int(700 * self.params.test_split * self.params.num_classes))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dp, \n",
    "                          batch_size = self.params.batch_size,\n",
    "                          num_workers = self.params.num_workers,\n",
    "                          shuffle = True)\n",
    "    \n",
    "    #def val_dataloader(self):\n",
    "        #return DataLoader(dataset = self.val_dp, \n",
    "                          #batch_size = self.params.batch_size,\n",
    "                          #num_workers = self.params.num_workers)\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset = self.test_dp, \n",
    "                          batch_size = self.params.batch_size,\n",
    "                          num_workers = self.params.num_workers)\n",
    "\n",
    "    def _set_label_encoder(self, dir_level_iter):\n",
    "        class_names = sorted([Path(path).stem for path in dir_level_iter])\n",
    "        self.label_encoder = LabelEncoder().fit(class_names)\n",
    "\n",
    "    def _train_test_split(self, path: str) -> int:\n",
    "        idx = int(path.split('/')[-1][:-4].split('_')[-1])\n",
    "        return int(idx <= 700 * self.params.test_split)\n",
    "\n",
    "    def _remote_datapipe(self):\n",
    "        connection_kwargs = {\"endpoint_url\": \"https://usc1.contabostorage.com\"}\n",
    "        pipe = dp.iter.FSSpecFileLister(self.root, **connection_kwargs) #type: ignore\n",
    "        self._set_label_encoder(iter(pipe))\n",
    "\n",
    "        pipe = dp.iter.FSSpecFileLister(pipe, **connection_kwargs)\n",
    "        #train_test_split\n",
    "        self.train_dp, self.test_dp = pipe.demux(num_instances=2, \n",
    "                                                 classifier_fn=self._train_test_split,\n",
    "                                                 buffer_size=700*self.params.num_classes) \n",
    "        self.train_dp = self.train_dp.open_files_by_fsspec(\"rb\", **connection_kwargs) # type: ignore\n",
    "        self.test_dp = self.test_dp.open_files_by_fsspec(\"rb\", **connection_kwargs) # type: ignore\n",
    "    \n",
    "    def _local_datapipe(self):\n",
    "        self._set_label_encoder(self.root.iterdir()) #type: ignore\n",
    "\n",
    "        pipe = dp.iter.FileLister(self.root.as_posix(), recursive=True) #type: ignore\n",
    "        self.train_dp, self.test_dp = pipe.demux(num_instances=2, \n",
    "                                                 classifier_fn=self._train_test_split,\n",
    "                                                 buffer_size=700*self.params.num_classes) \n",
    "        self.train_dp = self.train_dp.open_files(\"b\")\n",
    "        self.test_dp = self.test_dp.open_files(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Hyperparameters(\n",
    "    task = \"multiclass-classification\",\n",
    "    random_seed = 69,\n",
    "    num_classes = 45,\n",
    "    test_split = .25,\n",
    "    metrics = [\"accuracy\", \"f1score\"],\n",
    "    learning_rate = 1e-5,\n",
    "    batch_size = 64,\n",
    "    num_workers = 16,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    criterion = torch.nn.CrossEntropyLoss(),\n",
    ")\n",
    "\n",
    "resisc_dm = ResiscDataModule(RESISC, False, experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resisc_dm.setup(\"fit\")\n",
    "resisc_dl = resisc_dm.train_dataloader()\n",
    "len(resisc_dl)\n",
    "#viz_batch(next(iter(resisc_dl)), resisc_dm.label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame({\"image_path\": list((MLRSNET/\"Images\").rglob(\"*.jpg\"))})\n",
    "image_df[\"image\"] = image_df[\"image_path\"].apply(lambda x: x.name)\n",
    "image_df = image_df.set_index(\"image\")\n",
    "\n",
    "label_df = pd.concat([pd.read_csv(x) for x in (MLRSNET / \"Labels\").iterdir()])\n",
    "label_df = label_df.set_index(\"image\")\n",
    "\n",
    "assert len(label_df) == len(image_df), \"#images != #labels\"\n",
    "\n",
    "df = label_df.join(image_df, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to split train and test\n",
    "# Equal test samples (500?) from each class or proportional?\n",
    "# Instinct says equal\n",
    "label_df.sum(axis = 0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.sum(axis = 0).plot(kind = \"bar\", rot=90, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dp = dp.iter.IterableWrapper(df[\"image_path\"])\n",
    "label_dp = dp.iter.IterableWrapper(df.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(label_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_batch(batch: tuple[torch.Tensor, torch.Tensor], le: LabelEncoder) -> None:\n",
    "    images, targets = batch\n",
    "    labels = le.inverse_transform(targets.ravel())\n",
    "    assert images.shape[0] == targets.shape[0], \"#images != #targets\"\n",
    "\n",
    "    subplot_dims:tuple[int, int]\n",
    "    if images.shape[0] <= 8:\n",
    "        subplot_dims = (1, images.shape[0])\n",
    "    else:\n",
    "        subplot_dims = (int(np.ceil(images.shape[0]/8)), 8)\n",
    "\n",
    "    figsize = 20\n",
    "    figsize_factor = subplot_dims[0] / subplot_dims[1]\n",
    "    _, axes = plt.subplots(nrows = subplot_dims[0], \n",
    "                           ncols = subplot_dims[1], \n",
    "                           figsize = (figsize, figsize * figsize_factor))\n",
    "    for idx, ax in enumerate(axes.ravel()):\n",
    "        ax.imshow(images[idx].permute(1, 2, 0))\n",
    "        ax.tick_params(axis = \"both\", which = \"both\", \n",
    "                       bottom = False, top = False, \n",
    "                       left = False, right = False,\n",
    "                       labeltop = False, labelbottom = False, \n",
    "                       labelleft = False, labelright = False)\n",
    "        ax.set_xlabel(f\"{labels[idx]}({targets[idx].item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
